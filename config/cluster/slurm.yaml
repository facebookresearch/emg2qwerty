# @package _global_
defaults:
  - override /hydra/launcher: submitit_slurm

trainer:
  num_nodes: 1
  gpus: 8

# Due to ddp_spawn, larger num_workers together with larger trainer.gpus
# leads to massive slowdown
num_workers: 2

hydra:
  run:
    dir: /checkpoint/${env:USER}/emg2qwerty/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: /checkpoint/${env:USER}/emg2qwerty/${now:%Y-%m-%d}/${now:%H-%M-%S}
  launcher:
    submitit_folder: ${hydra.sweep.dir}/submitit_logs/%j
    nodes: ${trainer.num_nodes}
    gpus_per_node: ${trainer.gpus}
    tasks_per_node: 1
    cpus_per_task: 48
    partition: learnfair
